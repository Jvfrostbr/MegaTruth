import os
import sys
import time
from PIL import Image

import gradio as gr

# Garantir que o diret√≥rio `src` esteja no path para imports locais
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from models.vision_model_clip import CLIPAIModel
from models.multimodal_model_llava import LLaVAModel


# Diret√≥rios
os.makedirs("images", exist_ok=True)
os.makedirs("outputs/heatmaps", exist_ok=True)


# Inst√¢ncias de modelo (lazy loading)
clip_model = None
llava_model = None


def get_clip():
    """Carrega o modelo CLIP sob demanda."""
    global clip_model
    if clip_model is None:
        print("üîÑ Inicializando CLIP...")
        clip_model = CLIPAIModel()
    return clip_model


def get_llava():
    """Carrega o modelo LLaVA sob demanda."""
    global llava_model
    if llava_model is None:
        print("üîÑ Inicializando LLaVA via Ollama...")
        llava_model = LLaVAModel()
    return llava_model


def save_uploaded_image(img):
    """Salva imagem enviada no disco."""
    ts = int(time.time() * 1000)
    out_path = os.path.join("images", f"uploaded_{ts}.png")
    if isinstance(img, Image.Image):
        img.save(out_path)
    else:
        Image.fromarray(img).save(out_path)
    return out_path


def analyze_image(image):
    """Analisa imagem com CLIP e gera heatmap."""
    if image is None:
        return None, "‚ùå Erro", "Nenhuma imagem enviada", "", None, None
    
    try:
        # Salvar imagem
        img_path = save_uploaded_image(image)
        print(f"‚úÖ Imagem salva em: {img_path}")
        
        # Executar CLIP
        clip = get_clip()
        print(f"üìä Analisando com CLIP...")
        result = clip.predict_with_heatmap(img_path)
        
        # Extrair resultados
        label = result.get("label", "N/A")
        prob = result.get("probability", 0.0)
        conceitos = result.get("conceitos", {})  # Se dispon√≠vel
        overlay_path = result.get("overlay_path", None)
        
        # Carregar overlay/heatmap para exibi√ß√£o
        overlay_img = None
        if overlay_path and os.path.exists(overlay_path):
            overlay_img = Image.open(overlay_path).convert("RGB")
        
        # Formatar conceitos para exibi√ß√£o
        conceitos_text = ""
        if conceitos:
            conceitos_text = "\n".join([f"‚Ä¢ {k}: {v:.1%}" for k, v in list(conceitos.items())[:5]])
        else:
            conceitos_text = "Nenhum defeito espec√≠fico detectado"
        
        status_msg = f"‚úÖ An√°lise CLIP conclu√≠da\nüè∑Ô∏è {label}\nüìà Confian√ßa: {prob:.2%}"
        
        return img_path, label, f"{prob:.2%}", conceitos_text, overlay_img, status_msg

    except Exception as e:
        print(f"‚ùå Erro na an√°lise: {e}")
        return None, "‚ùå Erro", str(e), "", None, f"‚ùå Erro: {str(e)}"


def explain_with_llava(image_path, overlay_path, clip_label, clip_prob_str, conceitos_text):
    """Gera explica√ß√£o com LLaVA baseada na an√°lise CLIP."""
    try:
        if not image_path or not overlay_path:
            return "‚ùå Erro: Imagem ou overlay n√£o dispon√≠vel. Execute a an√°lise CLIP primeiro."
        
        if not os.path.exists(image_path) or not os.path.exists(overlay_path):
            return "‚ùå Erro: Arquivos de imagem ou overlay n√£o encontrados."
        
        # Limpar a probabilidade (remover %)
        prob_clean = clip_prob_str.replace("%", "").strip()
        try:
            prob_float = float(prob_clean) / 100.0
        except:
            prob_float = 0.0
        
        # Parsing de conceitos
        conceitos_dict = {}
        if conceitos_text and "‚Ä¢" in conceitos_text:
            for line in conceitos_text.split("\n"):
                if "‚Ä¢" in line:
                    try:
                        parts = line.split("‚Ä¢")[1].split(":")
                        if len(parts) == 2:
                            k = parts[0].strip()
                            v = float(parts[1].strip().replace("%", "")) / 100.0
                            conceitos_dict[k] = v
                    except:
                        pass
        
        print("üß† Chamando LLaVA para explica√ß√£o...")
        llava = get_llava()
        response = llava.analisar_imagens(
            imagem_original=image_path,
            heatmap=overlay_path,
            classificacao_clip=clip_label,
            probabilidade_clip=prob_float,
            conceitos_detectados=conceitos_dict if conceitos_dict else None
        )
        
        if response is None:
            return "‚ö†Ô∏è Nenhuma resposta do LLaVA. Verifique se o Ollama est√° rodando."
        
        return response

    except Exception as e:
        print(f"‚ùå Erro ao chamar LLaVA: {e}")
        return f"‚ùå Erro ao gerar explica√ß√£o: {str(e)}"


def build_ui():
    """Constr√≥i a interface Gradio."""
    with gr.Blocks(title="MegaTruth ‚Äî Detec√ß√£o de IA em Imagens") as demo:
        
        # ========== CABE√áALHO ==========
        gr.Markdown("""
        # MegaTruth ‚Äî Detec√ß√£o de Imagens Geradas por IA
        
        **Upload uma imagem** ‚Üí **An√°lise visual (CLIP)** ‚Üí **Explica√ß√£o em portugu√™s (LLaVA)**
        
        Este sistema detecta se uma imagem √© uma fotografia real ou gerada por IA, com heatmaps explicativos.
        """)
        
        # ========== SE√á√ÉO DE ENTRADA ==========
        gr.Markdown("### 1. Upload de Imagem")
        
        with gr.Row():
            image_input = gr.Image(
                type="pil",
                label="Envie sua imagem",
                sources=["upload", "clipboard"]
            )
            with gr.Column():
                analyze_btn = gr.Button(
                    "Analisar com CLIP",
                    size="lg",
                    variant="primary"
                )
                status_display = gr.Markdown("‚è≥ Aguardando...")
        
        # ========== SE√á√ÉO DE RESULTADOS CLIP ==========
        gr.Markdown("### 2. Resultados da An√°lise Visual (CLIP)")
        
        with gr.Row():
            col1, col2 = gr.Column(), gr.Column()
            
            with col1:                
                heatmap_display = gr.Image(
                    label="Heatmap de Ativa√ß√£o",
                    interactive=False
                )
            
            with col2:
                label_display = gr.Textbox(
                    label="Classifica√ß√£o",
                    interactive=False,
                    lines=1
                )
            
                prob_display = gr.Textbox(
                    label="üìà Confian√ßa",
                    interactive=False,
                    lines=1
                )
                
                conceitos_display = gr.Textbox(
                    label="Padr√µes Detectados (Concept Analysis)",
                    interactive=False,
                    lines=4
                )
         
        # ========== SE√á√ÉO DE EXPLICA√á√ÉO ==========
        gr.Markdown("### 3. Explica√ß√£o Detalhada (LLaVA)")
        
        explain_btn = gr.Button(
            "Gerar Explica√ß√£o com LLaVA",
            size="lg",
            variant="secondary"
        )
        
        explanation_display = gr.Textbox(
            label="An√°lise Forense Detalhada",
            lines=12,
            interactive=False
        )
        
        # ========== L√ìGICA DE EVENTOS ==========
        
        # Estado interno para rastrear valores
        state_image_path = gr.State(value=None)
        state_overlay_path = gr.State(value=None)
        state_label = gr.State(value="")
        state_prob = gr.State(value="")
        state_conceitos = gr.State(value="")
        
        def on_analyze(image):
            """Callback do bot√£o 'Analisar'."""
            img_path, label, prob, conceitos, overlay, status = analyze_image(image)
            
            # Armazenar overlay_path: como overlay √© PIL.Image, precisamos salvar
            overlay_path = None
            if overlay is not None:
                overlay_path = save_uploaded_image(overlay)
            
            # Retornar na ordem exata dos outputs
            return img_path, overlay_path, label, prob, conceitos, overlay, status, label, prob, conceitos, "‚è≥ Aguardando explica√ß√£o..."
        
        # Conectar bot√£o de an√°lise
        analyze_btn.click(
            fn=on_analyze,
            inputs=[image_input],
            outputs=[
                state_image_path, state_overlay_path, state_label, state_prob, state_conceitos,
                heatmap_display, status_display, label_display, prob_display, conceitos_display, explanation_display
            ]
        )
        
        def on_explain(img_path, overlay_path, label, prob, conceitos):
            """Callback do bot√£o 'Gerar Explica√ß√£o'."""
            if not img_path or not overlay_path:
                return "Erro: Execute a an√°lise CLIP primeiro."
            
            explanation = explain_with_llava(img_path, overlay_path, label, prob, conceitos)
            return explanation
        
        # Conectar bot√£o de explica√ß√£o
        explain_btn.click(
            fn=on_explain,
            inputs=[state_image_path, state_overlay_path, state_label, state_prob, state_conceitos],
            outputs=[explanation_display]
        )
    
    return demo


if __name__ == "__main__":
    app = build_ui()
    print("\n" + "="*60)
    print("Iniciando MegaTruth (Gradio)")
    print("="*60)
    print("Acesse em: http://127.0.0.1:7860")
    print("="*60 + "\n")
    
    app.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,
        show_error=True
    )
